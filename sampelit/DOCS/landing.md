# Live Copy Experiment

## Hero Section

**This page is running a live copy experiment.**

You are currently seeing:  
**Variant #4 of 9**

Other visitors see different versions.

We test our own landing pages with the same system we offer.

No demos. No promises.  
Just real traffic and real data.

**Primary CTA:** See the live simulation  
**Secondary CTA:** Calculate potential impact

---

## What's Happening Here

Every visitor does not see the same page.

This landing has **9 active copy variants:**
- Different headlines
- Different CTAs
- Same structure

Traffic is distributed automatically.  
Performance is measured continuously.

**You are part of the experiment.**

---

## Live Simulation (Based on Real Tests)

### Adaptive Optimization vs Traditional Testing

**Traditional A/B testing:**
- Fixed traffic split (50/50 or 33/33/33)
- All variants receive equal traffic
- Losing variants keep wasting visitors

Example:
- Variant A: 1,333 visits → 3.1% CR
- Variant B: 1,333 visits → 4.2% CR
- Variant C: 1,333 visits → 2.9% CR

**Adaptive optimization:**
- Traffic reallocated based on performance
- Strong variants receive more exposure
- Weak variants fade out naturally

Example:
- Variant A: 820 visits → 3.1% CR
- Variant B: 2,050 visits → 4.2% CR
- Variant C: 1,130 visits → 2.9% CR

### Result

Same traffic. Same variants. Same conversion rates.  
**Only difference:** How traffic is distributed.

**Outcome:**
- Traditional testing: 158 conversions
- Adaptive optimization: 181 conversions
- **Impact: +14.5% conversions**

*This is a modeled simulation using realistic ranges. Individual results vary based on traffic and variance.*

---

## Estimate the Impact on Your Site

A modeled estimation based on controlled copy experiments.  
**Not a promise. A calculation.**

### Your Inputs

**Monthly visitors:** [3000]  
**Current conversion rate (%):** [3.0]  
☑ I don't know my conversion rate *(Auto-set to 2.5%)*

**Average order value (€):** [100]

**CTA:** Calculate estimate

### Your Current Estimated Performance

3,000 visitors × 3.0% × €100  
= **€9,000 / month**

### Modeled Improvement from Copy Testing

Based on typical uplifts observed in controlled experiments.

**Scenario A — Conservative**  
+0.5% absolute CR (3.0% → 3.5%)  
+€1,500 / month | +€18,000 / year

**Scenario B — Typical**  
+1.0% absolute CR (3.0% → 4.0%)  
+€3,000 / month | +€36,000 / year

**Scenario C — Upper range**  
+1.5% absolute CR (3.0% → 4.5%)  
+€4,500 / month | +€54,000 / year

*These are absolute improvements, not relative percentages.*

### Cost vs Potential Upside

Estimated annual tool cost: **€588 / year**  
Potential annual upside: **€18,000 – €54,000**

*This is not guaranteed. It represents the cost of not knowing which copy performs better.*

---

## See How This Is Tested in Practice

We're running a live copy experiment.

You can observe:
- How traffic is distributed
- How variants gain or lose exposure
- When results become statistically meaningful

**Email address:** [___________]

**CTA:** Send me the experiment updates

*No spam. No sales emails. We only write when there is something to learn.*

---

## Why This Matters

If you don't test your copy:
- You don't know which version performs better
- You choose based on intuition
- You leave revenue unexplained

Testing doesn't create demand.  
**It removes uncertainty.**

---

## Transparency Note

- No personal data is collected
- Results are aggregated
- Metrics are delayed for integrity
- Optimization logic is proprietary

This experiment is public.  
The system behind it is controlled.

---

## Testing Methodology

**Experiment design:**  
Each experiment runs with multiple copy variants shown to real users.
- Initial traffic is distributed evenly
- All variants measure the same conversion event
- No visual or layout changes are introduced

**Traffic allocation:**  
Traffic distribution adapts based on observed performance.
- Underperforming variants receive less traffic over time
- Higher-performing variants receive more traffic
- Exploration is maintained to avoid premature conclusions

**Statistical confidence:**  
A variant is declared a winner only when confidence thresholds are met.
- Minimum sample size enforced
- Confidence level displayed (e.g. 95%, 97%)
- No winners declared without sufficient data

**Data integrity & privacy:**  
- No personal data is stored or processed
- Only aggregated performance metrics
- No cookies required
- GDPR-compliant by design

**Manual control:**  
All experiments can be paused, modified or stopped at any time.
- No lock-in
- No forced implementation
- Final decision always remains with the user

---

**Footer:** Live experiment · Data-driven · 2025  
Privacy · Terms · Contact
